# SPDX-FileCopyrightText: Copyright (c) 2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# SPDX-License-Identifier: Apache-2.0

# This workflow demonstrates distributed data upload/download using OSMO Data Express
#
# The workflow consists of three components:
# - Redis server: Coordinates work distribution between components
# - Lister: Scans input location and creates work items by chunking files
# - Workers: Multiple processes that perform the actual data transfer
#
# Required parameters:
# - service_url: OSMO service URL (e.g. https://osmo.nvidia.com)
# - worker_process_count: Number of CPU cores for parallel processing
# - source_path: Source path to upload/download data from
# - destination_path: Destination path to upload/download data to
#
# Example usage:
# $ export SERVICE_URL=https://osmo.nvidia.com
# $ export INPUT_LOCATION=/data/input
# $ export OUTPUT_LOCATION=s3://my-bucket/data
# $ osmo workflow submit data-express.yaml \
#     --set service_url=$SERVICE_URL \
#     input_location=$INPUT_LOCATION \
#     output_location=$OUTPUT_LOCATION \
#     num_workers=4

version: 2
workflow:
  name: data-express
  resources:
    lister:
      cpu: 1
      storage: 2Gi
      memory: 4Gi
    redis:
      cpu: 1
      storage: 2Gi
      memory: 4Gi
    worker:
      cpu: {{worker_process_count}}
      storage: 2Gi
      memory: {{worker_memory}}

  groups:
  - name: group1
    tasks:
    # Redis task: Runs a Redis server for coordinating work between components
    - name: redis
      image: redis:7.0
      command: [redis-server]
      resource: redis

    # Lister task: Scans the input location and creates work items for workers
    # - Lists all files that need to be processed
    # - Chunks the work into manageable pieces
    # - Coordinates with Redis to distribute work to workers
    - name: lister
      image: python:3.10
      resource: lister
      lead: true
      command: [bash]
      args: ['/tmp/run.sh']
      files:
      - contents: |
          set -ex

          export OSMO_WORKFLOW_DATA_HEADER=osmo-background-job

          pip3 install kombu==5.2.4 pydantic==1.10.13 redis==4.4.4
          pip3 install \
            --upgrade \
            --extra-index-url={{service_url}}/client/pypi/simple \
            nvidia-osmo

          python3 -u /tmp/lister.py {{input_location}} {{output_location}} \
            --benchmark-location {{output}} \
            --redis-url redis://{{host:redis}}:6379 \
            --max-chunk-size {{max_chunk_size}} --max-chunk-amount {{max_chunk_amount}}
        path: /tmp/run.sh
      - path: /tmp/lister.py
        localpath: ./scripts/lister.py
      - path: /tmp/data_utils.py
        localpath: ./scripts/data_utils.py
      {% if benchmark_location != "" %}
      outputs:
      - url: {{benchmark_location}}
      {% endif %}

    # Worker tasks: Multiple workers that process the data in parallel
    # - Each worker picks up work items from Redis
    # - Handles the actual data transfer operations
    # - Can be scaled by adjusting num_workers
    {% for i in range(num_workers) %}
    - name: worker-{{i}}
      image: python:3.10
      resource: worker
      command: [bash]
      args: [/tmp/run.sh]
      files:
      - contents: |
          set -ex
          export PYTHONUNBUFFERED=1
          export OSMO_DATA_CLIENT_VERBOSE=True
          export OSMO_DATA_CLIENT_NUM_THREADS={{worker_thread_count}}
          export OSMO_WORKFLOW_DATA_HEADER=osmo-background-job

          pip3 install kombu==5.2.4 pydantic==1.10.13 redis==4.4.4
          pip3 install \
            --upgrade \
            --extra-index-url={{service_url}}/client/pypi/simple \
            nvidia-osmo

          python3 -u /tmp/worker.py {{input_location}} {{output_location}} \
            --redis-url redis://{{host:redis}}:6379
        path: /tmp/run.sh
      - path: /tmp/worker.py
        localpath: ./scripts/worker.py
      - path: /tmp/data_utils.py
        localpath: ./scripts/data_utils.py
    {% endfor %}

default-values:
  # Service URL
  service_url: "https://osmo.nvidia.com"

  # Number of parallel worker tasks to spawn
  num_workers: 4

  # Data source and destination paths
  input_location: "/inside/workflow/folder/path/to/data"
  output_location: "s3://bucket/path/to/data"

  # Optional location for storing benchmark results
  benchmark_location: ""

  # Performance tuning parameters
  max_chunk_size: 100Gi    # Maximum size of each work chunk
  max_chunk_amount: 10000    # Maximum number of items in each chunk
  worker_process_count: 4  # Number of CPU cores per worker
  worker_thread_count: 20  # Number of concurrent threads per worker
  worker_memory: 100Gi
