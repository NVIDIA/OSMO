# SPDX-FileCopyrightText: Copyright (c) 2026 NVIDIA CORPORATION. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# SPDX-License-Identifier: Apache-2.0

# syntax=docker/dockerfile:1.4

# =============================================================================
# BUILD COMMANDS
# =============================================================================
#
# Standard build for Kubernetes (from Apple Silicon Mac):
#   cd external/ui-next
#   docker login nvcr.io
#   docker buildx build --platform linux/amd64 \
#     -t nvcr.io/nvstaging/osmo/web-ui-next:YOUR_TAG .
#   docker push nvcr.io/nvstaging/osmo/web-ui-next:YOUR_TAG
#
# Build for Kubernetes (from Linux/Intel Mac):
#   docker build -t nvcr.io/nvstaging/osmo/web-ui-next:YOUR_TAG .
#   docker push nvcr.io/nvstaging/osmo/web-ui-next:YOUR_TAG
#
# Multi-arch build (supports both amd64 and arm64 clusters):
#   docker buildx build --platform linux/amd64,linux/arm64 \
#     -t nvcr.io/nvstaging/osmo/web-ui-next:YOUR_TAG --push .
#
# Build with custom basePath (e.g., for canonical deployment at /):
#   docker build --build-arg NEXT_PUBLIC_BASE_PATH="" \
#     -t nvcr.io/nvstaging/osmo/web-ui-next:YOUR_TAG .
#
# Build with source maps enabled (for debugging):
#   docker build --build-arg ENABLE_SOURCE_MAPS=true \
#     -t nvcr.io/nvstaging/osmo/web-ui-next:YOUR_TAG .
#
# Note: Backend API hostname is configured at RUNTIME via Kubernetes environment
# variables (NEXT_PUBLIC_OSMO_API_HOSTNAME), not at build time. This makes the
# Docker image portable across environments - critical for open source deployment.
#
# Debug build (no cache, verbose output):
#   docker build --no-cache --progress=plain -t web-ui-next:debug .
#
# =============================================================================

# =============================================================================
# Stage 1: Dependencies (cached unless package.json/pnpm-lock.yaml change)
# =============================================================================
FROM node:22-slim AS deps

# Enable corepack for pnpm (reads version from package.json packageManager field)
RUN corepack enable

WORKDIR /app

# Copy ONLY dependency files first (maximizes cache hits)
COPY package.json pnpm-lock.yaml ./

# Create public directory for postinstall script
RUN mkdir -p public

# Install dependencies with BuildKit cache mount (persists pnpm store between builds)
# The postinstall script will copy elk-worker.min.js to public/ during install
RUN --mount=type=cache,id=pnpm,target=/root/.local/share/pnpm/store \
    pnpm install --frozen-lockfile

# =============================================================================
# Stage 2: Build (rebuilds when source changes, but deps are cached)
# =============================================================================
FROM node:22-slim AS builder

RUN corepack enable

WORKDIR /app

# Copy dependencies from deps stage
COPY --from=deps /app/node_modules ./node_modules

# Copy source files
COPY package.json pnpm-lock.yaml next.config.ts tsconfig.json postcss.config.mjs ./
COPY src ./src
COPY scripts ./scripts

# Copy public files from source (committed files like favicon.ico)
# Note: mockServiceWorker.js is excluded via .dockerignore (dev-only, aliased out in prod)
COPY public ./public

# CRITICAL: Copy postinstall-generated files from deps stage (elk-worker.min.js, etc.)
# This overlay ensures files generated by postinstall in deps stage are included
# Without this, the postinstall script would run again in builder stage but fail
# because node_modules is copied without running install (no postinstall trigger)
COPY --from=deps /app/public/ ./public/

# =============================================================================
# Build Arguments - Can be overridden at build time
# =============================================================================
# Example: docker build --build-arg NEXT_PUBLIC_BASE_PATH="" .
#
# BasePath for UI deployment (e.g., /v2 for dual deployment, "" for canonical)
ARG NEXT_PUBLIC_BASE_PATH=/v2

# Enable source maps in production (disabled by default for faster builds)
ARG ENABLE_SOURCE_MAPS=false

# Disable Next.js telemetry in CI/CD builds
ARG NEXT_TELEMETRY_DISABLED=1

# =============================================================================
# Set build environment variables
# =============================================================================
# Convert ARGs to ENVs so Next.js build process can access them via process.env
#
# Note: NEXT_PUBLIC_OSMO_API_HOSTNAME and NEXT_PUBLIC_OSMO_SSL_ENABLED are
# intentionally NOT set at build time. They are read at RUNTIME from the
# container environment, making the Docker image portable across environments.
# This is critical for open source deployment where backend hostname varies.

ENV NEXT_PUBLIC_BASE_PATH=${NEXT_PUBLIC_BASE_PATH}
ENV ENABLE_SOURCE_MAPS=${ENABLE_SOURCE_MAPS}
ENV NEXT_TELEMETRY_DISABLED=${NEXT_TELEMETRY_DISABLED}
ENV NODE_ENV=production

# =============================================================================
# Build Next.js application
# =============================================================================
# BuildKit cache mount persists .next/cache between builds for faster rebuilds
RUN --mount=type=cache,target=/app/.next/cache \
    pnpm build

# =============================================================================
# Stage 2.5: Prepare cache directory (has shell for mkdir/chown)
# =============================================================================
FROM node:22-slim AS cache-prep

# Create cache directory with correct ownership
# Using UID 1000 to match Kubernetes deployment's runAsUser setting
RUN mkdir -p /cache && \
    touch /cache/.gitkeep && \
    chown -R 1000:1000 /cache

# =============================================================================
# Stage 3: Production image (same base as legacy UI)
# =============================================================================
# Uses same NVIDIA distroless image as legacy UI (see external/MODULE.bazel:295-303)
FROM nvcr.io/nvidia/distroless/node:22-v3.1.1 AS runner

WORKDIR /app

# Copy standalone output (matches legacy UI structure)
COPY --from=builder /app/.next/standalone ./
COPY --from=builder /app/.next/static ./.next/static
COPY --from=builder /app/public ./public

# Copy cache directory from cache-prep stage (with correct permissions)
# Must be done before switching to nonroot user to ensure proper permissions
COPY --from=cache-prep --chown=1000:1000 /cache ./.next/cache

# =============================================================================
# Runtime Environment Variables
# =============================================================================
# These can be overridden at runtime via Helm chart values (extraEnvs)
# Note: NEXT_PUBLIC_* vars set at build time are baked into the bundle
#       Runtime overrides only work for server-side code, not client-side

ENV HOSTNAME=0.0.0.0
ENV NODE_ENV=production
ENV NEXT_PUBLIC_APP_NAME=OSMO

# Optional: Set default runtime values (can be overridden by Kubernetes)
# ENV NEXT_PUBLIC_BASE_PATH=/v2
# ENV NEXT_PUBLIC_OSMO_API_HOSTNAME=osmo-service.osmo.svc.cluster.local:80
# ENV NEXT_PUBLIC_OSMO_SSL_ENABLED=false

USER nonroot

# Match legacy UI pattern: entrypoint=node, cmd=server.js
ENTRYPOINT ["node"]
CMD ["server.js"]
